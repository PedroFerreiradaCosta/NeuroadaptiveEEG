{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceShiftBirkbeck.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedroFerreiradaCosta/NeuroadaptiveEEG/blob/main/FaceShiftBirkbeck.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s9q1fmKkQFX"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/PedroFerreiradaCosta/FaceFitOpt/master/Figures/facefitopt_logo.png\" alt=\"FaceFitOpt Logo\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkdVmB0wI8wG",
        "cellView": "form"
      },
      "source": [
        "#@markdown #**Load pictures and generate images between the two faces**\n",
        "\n",
        "# Clone my repo\n",
        "!git clone https://github.com/PedroFerreiradaCosta/stylegan-encoder.git\n",
        "import os\n",
        "os.chdir(\"stylegan-encoder\")\n",
        "\n",
        "# Import dependencies\n",
        "%tensorflow_version 1.x\n",
        "import pickle\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import config\n",
        "from encoder.generator_model import Generator\n",
        "from google.colab import files\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "# path to model code and weight\n",
        "path_model = 'https://drive.google.com/uc?id=1I1vyhKJhoQul3ryIrHcTlpYycPAhWooI'\n",
        "\n",
        "\n",
        "\"\"\" create tf session \"\"\"\n",
        "yn_CPU_only = False\n",
        "\n",
        "if yn_CPU_only:\n",
        "    config = tf.ConfigProto(device_count = {'GPU': 0}, allow_soft_placement=True)\n",
        "else:\n",
        "    config = tf.ConfigProto(allow_soft_placement=True)\n",
        "    config.gpu_options.allow_growth = True\n",
        "\n",
        "sess = tf.InteractiveSession(config=config)\n",
        "\n",
        "try:\n",
        "    with dnnlib.util.open_url(path_model, 'rb') as file:\n",
        "        G, D, Gs = pickle.load(file)\n",
        "except FileNotFoundError:\n",
        "    print('before running the code, download pre-trained model to project_root/asset_model/')\n",
        "    raise\n",
        "\n",
        "\n",
        "try:\n",
        "  generator = Generator(Gs, batch_size=1, randomize_noise=False)\n",
        "except ValueError:\n",
        "  print(\"Restarting session. Run code again\")\n",
        "  os.kill(os.getpid(), 9)\n",
        "\n",
        "  # Pick latent vector.\n",
        "rnd = np.random.RandomState(5)\n",
        "latents = rnd.randn(1, Gs.input_shape[1])\n",
        "\n",
        "# Generate image.\n",
        "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=True, output_transform=fmt)\n",
        "images = tflib.convert_images_to_uint8(images)\n",
        "  \n",
        "def generate_image(latent_vector, i):\n",
        "    latent_vector = latent_vector.reshape((1, 18, 512))\n",
        "    generator.set_dlatents(latent_vector)\n",
        "    img_array = generator.generate_images()[0]\n",
        "    img = PIL.Image.fromarray(img_array, 'RGB')\n",
        "    img.save(\"tmp{:02d}.png\".format(i+1))\n",
        "    return img.resize((256, 256))\n",
        "\n",
        "\n",
        "# Create folders to align and generate artificial image\n",
        "image_path = Path.cwd()\n",
        "Path.mkdir(image_path / 'aligned_images', exist_ok=True)\n",
        "Path.mkdir(image_path / 'generated_images', exist_ok=True)\n",
        "Path.mkdir(image_path / 'raw_images', exist_ok=True)\n",
        "\n",
        "try:\n",
        "  path_to_remove = Path(image_path / 'raw_images' / '.ipynb_checkpoints')\n",
        "  path_to_remove.rmdir()\n",
        "except FileNotFoundError:\n",
        "  print('No such file exists.')\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "def upload_files():\n",
        "  uploaded = files.upload()\n",
        "  for k, v in uploaded.items():\n",
        "    open(f'raw_images/{k}', 'wb').write(v)\n",
        "  return list(uploaded.keys())\n",
        "\n",
        "if os.listdir('raw_images/')==[]:\n",
        "  uploaded_images = upload_files()\n",
        "else:\n",
        "  for i in os.listdir('raw_images/'):\n",
        "    os.remove(i)\n",
        "  uploaded_images = upload_files()\n",
        "# 1) Extract and align faces from images\n",
        "# Images to be processed should be added to the folder 'raw_images'\n",
        "!python align_images.py raw_images/ aligned_images/\n",
        "# if downloading dlib face landmarks takes more than 1/2 min, rerun code\n",
        "\n",
        "# 2) Find latent representation of aligned images\n",
        "!python encode_images.py aligned_images/ generated_images/ latent_representations/ --iterations 500\n",
        "\n",
        "\n",
        "# src_dir - directory with images\n",
        "# generaed_miages_dir - disrectory for storing generated images\n",
        "# dlatent_dir - directory for storing dlatent representations\n",
        "# batch_size - df - 1 - for generator and perceptual model\n",
        "# image_size - df - 256 - Size of images for perceptual model\n",
        "# lr - df 1 - learning rate for perc. model\n",
        "# iterations - df - 1000 - opetimizations steps per batch \n",
        "# randomize_noise-  df - False - add noise to dlatents during optimization\n",
        "\n",
        "# Load results\n",
        "mom = np.load(f'latent_representations/{uploaded_images[0][:-4]}_01.npy')\n",
        "notmom = np.load(f'latent_representations/{uploaded_images[1][:-4]}_01.npy')\n",
        "\n",
        "# Print and download (10 a.t.m.)\n",
        "alpha = [1,0.88,0.77,0.66,0.55,0.44,0.33,0.22,0.11, 0]\n",
        "for i in range(len(alpha)):\n",
        "    plt.figure()\n",
        "    new_latent_vector = (alpha[i]*mom)+((1-(alpha[i]))*notmom)\n",
        "    plt.imshow(generate_image(new_latent_vector, i))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    files.download(\"tmp{:02d}.png\".format(i+1)) \n",
        "\n",
        "# download originals\n",
        "os.rename(f'aligned_images/{uploaded_images[0][:-4]}_01.png', 'tmp00.png')\n",
        "os.rename(f'aligned_images/{uploaded_images[1][:-4]}_01.png', 'tmp11.png')\n",
        "files.download(\"tmp00.png\")\n",
        "files.download(\"tmp11.png\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}